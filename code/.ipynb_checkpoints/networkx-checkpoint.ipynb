{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import networkx as nx \n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(47,51):\n",
    "    base_str = 'C:\\\\Users\\\\raosa\\\\Dropbox\\\\data\\\\combined\\\\'\n",
    "    data = pd.read_csv('C:\\\\Users\\\\raosa\\\\Dropbox\\\\dl-graph\\\\data\\\\eth\\\\pricing\\\\final.csv')\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    x=pd.read_csv(str(base_str+str(m)+'.csv'))\n",
    "    print('reading done')\n",
    "    print(len(x))\n",
    "    timestamp_list = x['timestamp']\n",
    "    value_list = x['value']\n",
    "\n",
    "    timestamp_list_1=[]\n",
    "    value_list_1=[]\n",
    "    print('transaction loop starting')\n",
    "    for i in  range(0,len(timestamp_list)):\n",
    "        test1 = datetime.fromtimestamp(int(str(timestamp_list[i]),16))\n",
    "        test2 = (int(x['value'][i],16))/1000000000000000000\n",
    "        timestamp_list_1.append(test1)\n",
    "        value_list_1.append(test2)\n",
    "    print('transaction loop done')\n",
    "    x['timestamp1'] = timestamp_list_1\n",
    "    x['value1'] = value_list_1\n",
    "\n",
    "\n",
    "    x=x.drop(['timestamp','value'],axis=1)\n",
    "    x = x.rename(columns={'timestamp1': 'timestamp', 'value1': 'value'})\n",
    "\n",
    "\n",
    "\n",
    "        #     value_list = x['value']\n",
    "        #     for i in range(0,len(x)): \n",
    "        #         x['timestamp1'] = datetime.datetime.fromtimestamp(int(str(x['timestamp'][i]),16))\n",
    "        #         x['value1'][i] = int(x['value'][i],16)\n",
    "\n",
    "        #     print('for loop done')\n",
    "    x['timestamp'] = pd.to_datetime(x['timestamp'])\n",
    "\n",
    "\n",
    "    edge_count = []\n",
    "    node_count = []\n",
    "    degree = []\n",
    "    print('network loop starting')\n",
    "    for k in range(0,len(data)):\n",
    "        time_start = data['Date'][k]\n",
    "        time_end = data['Date'][k] + timedelta(hours=1)\n",
    "\n",
    "        hour_tranlist = x[(x['timestamp'] > time_start) & (x['timestamp'] < time_end)]\n",
    "\n",
    "        list1 = hour_tranlist['from']\n",
    "        list2 = hour_tranlist['to']\n",
    "        nodes = list(set(list1 + list2))\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(nodes)\n",
    "        G.add_edges_from(list(zip(list1,list2)),weight=x['value'])\n",
    "        nx.write_gexf\n",
    "        edge_count.append(nx.number_of_edges(G))\n",
    "        node_count.append(nx.number_of_nodes(G))\n",
    "        # average degree of the network \n",
    "        if(nx.number_of_nodes(G)==0):\n",
    "            degree.append('0')\n",
    "        else:\n",
    "            degree.append(sum(dict(G.degree()).values()) / nx.number_of_nodes(G))\n",
    "    print('network loop done')\n",
    "    data['edge_count']=edge_count\n",
    "    data['node_count']=node_count\n",
    "    data['degree']=degree\n",
    "    data= data[data[\"node_count\"] != 0]\n",
    "    data.to_csv(str('network_'+str(m)+'.csv'),index=False)\n",
    "    print(m)\n",
    "    print('______________________')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_start = data['Date'][1300]\n",
    "time_end = time_start + timedelta(hours=1)\n",
    "\n",
    "hour_tranlist = x[(x['timestamp'] > time_start) & (x['timestamp'] < time_end)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['edge_count']=edge_count\n",
    "data['node_count']=node_count\n",
    "data['degree']=degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data being read\n",
      "reading done\n",
      "17692247\n",
      "transaction loop starting\n",
      "transaction loop done\n",
      "network loop starting\n",
      "21071\n",
      "network loop done\n",
      "50\n",
      "______________________\n"
     ]
    }
   ],
   "source": [
    "for m in range(50,51):\n",
    "    base_str = 'C:\\\\Users\\\\raosa\\\\Dropbox\\\\data\\\\combined\\\\'\n",
    "    print('data being read')\n",
    "    data = pd.read_csv('C:\\\\Users\\\\raosa\\\\Dropbox\\\\dl-graph\\\\data\\\\eth\\\\pricing\\\\final.csv')\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    x=pd.read_csv(str(base_str+str(m)+'.csv'))\n",
    "    print('reading done')\n",
    "    print(len(x))\n",
    "    timestamp_list = x['timestamp']\n",
    "    value_list = x['value']\n",
    "\n",
    "    timestamp_list_1=[]\n",
    "    value_list_1=[]\n",
    "\n",
    "    print('transaction loop starting')\n",
    "    for i in  range(0,len(timestamp_list)):\n",
    "        test1 = datetime.fromtimestamp(int(str(timestamp_list[i]),16))\n",
    "        test2 = (int(x['value'][i],16))/1000000000000000000\n",
    "        timestamp_list_1.append(test1)\n",
    "        value_list_1.append(test2)\n",
    "    print('transaction loop done')\n",
    "\n",
    "\n",
    "    x=x.drop(['timestamp','value'],axis=1)\n",
    "    x = x.rename(columns={'timestamp1': 'timestamp', 'value1': 'value'})\n",
    "    x['timestamp']= timestamp_list_1\n",
    "    x['value'] = value_list_1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    edge_count = []\n",
    "    node_count = []\n",
    "    degree = []\n",
    "    transitivity = []\n",
    "    average_clustering = []\n",
    "    diameter = []\n",
    "    radius = []\n",
    "    average_shortest_path_length=[]\n",
    "    density = []\n",
    "    betweenness_centrality = []\n",
    "    estrada_index = []\n",
    "    centrality = []\n",
    "    degree_pearson_correlation_coefficient = []\n",
    "    number_connected_components = []\n",
    "\n",
    "    print('network loop starting')\n",
    "    for k in range(0,len(data)):\n",
    "        time_start = data['Date'][k]\n",
    "        time_end = data['Date'][k] + timedelta(hours=1)\n",
    "\n",
    "        hour_tranlist = x[(x['timestamp'] > time_start) & (x['timestamp'] < time_end)]\n",
    "\n",
    "        list1 = hour_tranlist['from']\n",
    "        list2 = hour_tranlist['to']\n",
    "        nodes = list(set(list1 + list2))\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(nodes)\n",
    "        G.add_edges_from(list(zip(list1,list2)),weight=x['value'])\n",
    "\n",
    "        edge_count.append(nx.number_of_edges(G))\n",
    "        node_count.append(nx.number_of_nodes(G))\n",
    "    #     average_clustering_internal = []\n",
    "\n",
    "\n",
    "    #     for g in nx.connected_component_subgraphs(G):\n",
    "    #         average_clustering_internal.append(nx.average_clustering(g))\n",
    "    #         radius_internal.append(nx.radius(g))\n",
    "    #     average_clustering.append(max(average_clustering_internal))\n",
    "    #     radius.append(max(radius_internal))\n",
    "            # average degree of the network \n",
    "        if(nx.number_of_nodes(G)==0):\n",
    "                degree.append('0')\n",
    "                transitivity.append('0')\n",
    "                density.append('0')\n",
    "                centrality.append('0')\n",
    "                average_clustering.append('0')\n",
    "                degree_pearson_correlation_coefficient.append('0')\n",
    "                number_connected_components.append('0')\n",
    "    #             diameter.append('0')\n",
    "    #             average_shortest_path_length.append('0')\n",
    "    #             betweenness_centrality.append('0')\n",
    "    #             radius.append('0')\n",
    "        else:\n",
    "            degree.append(sum(dict(G.degree()).values()) / nx.number_of_nodes(G))\n",
    "            transitivity.append(nx.transitivity(G))\n",
    "    #         average_clustering.append(nx.average_clustering(G,weight=x['value']))\n",
    "    #         diameter.append(nx.diameter(G))\n",
    "    #         average_shortest_path_length.append(nx.average_shortest_path_length(G,weight=x['value']))\n",
    "            density.append(nx.density(G))\n",
    "            average_clustering.append(nx.average_clustering(G))\n",
    "            degree_pearson_correlation_coefficient.append(nx.degree_pearson_correlation_coefficient(G))\n",
    "            number_connected_components.append(nx.number_connected_components(G))\n",
    "    #         radius.append(nx.radius(G))\n",
    "    #         print(nx.betweenness_centrality(G,weight=x['value']))betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None)\n",
    "            centrality.append(max(nx.eigenvector_centrality_numpy(G).values()))\n",
    "\n",
    "\n",
    "    print(k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('network loop done')\n",
    "\n",
    "\n",
    "\n",
    "    data['edge_count']=edge_count\n",
    "    data['node_count']=node_count\n",
    "    data['degree']=degree\n",
    "    data['transitivity'] = transitivity\n",
    "    data['centrality'] = centrality\n",
    "    data['average_clustering'] = average_clustering\n",
    "    data['number_connected_components'] = number_connected_components\n",
    "    # data['diameter'] = diameter\n",
    "    # data['average_shortest_path_length'] = average_shortest_path_length\n",
    "    data['density']= density\n",
    "    data= data[data[\"node_count\"] != 0]\n",
    "\n",
    "    data.to_csv(str('network_'+str(m)+'.csv'),index=False)\n",
    "    print(m)\n",
    "    print('______________________')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features I already have outputted out \n",
    "# count , close price , edge_count , node_count , degree\n",
    "\n",
    "# new features I added \n",
    "# transitivity , density , centrality , average_clustering , degree_pearson_correlation_coefficient \n",
    "# ,number_connected_components\n",
    "\n",
    "# features to be added \n",
    "# radius , average shortest path length \n",
    "\n",
    "# features that cannot be added\n",
    "# betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # betweenness centrality , note , have to take care of if division by zero error occurs\n",
    "# nx.betweenness_centrality(G,weight=x['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to load individual files , combine them , remove columns we do not need and output them .  \n",
    "import pandas as pd \n",
    "base_str = 'C:\\\\Users\\\\raosa\\\\Desktop\\\\merged\\\\networkx_p2\\\\'\n",
    "transaction_str = 'network_'\n",
    "\n",
    "\n",
    "tran={}\n",
    "df={}\n",
    "for i in range(1,51):\n",
    "    \n",
    "    tran[i] = pd.read_csv(str(base_str+transaction_str+str(i)+'.csv'))\n",
    "    \n",
    "\n",
    "tran_concat = [tran[i] for i in range(1,51)]\n",
    "\n",
    "tran=pd.concat(tran_concat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.to_csv('part1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "base_str = 'C:\\\\Users\\\\raosa\\\\Desktop\\\\merged\\\\counts\\\\'\n",
    "transaction_str = 'count_'\n",
    "\n",
    "\n",
    "tran={}\n",
    "df={}\n",
    "for i in range(1,51):\n",
    "    \n",
    "    tran[i] = pd.read_csv(str(base_str+transaction_str+str(i)+'.csv'))\n",
    "    \n",
    "\n",
    "tran_concat = [tran[i] for i in range(1,51)]\n",
    "\n",
    "counts=pd.concat(tran_concat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.to_csv('part2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_csv('part1.csv')\n",
    "p2 = pd.read_csv('part2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>log_ret</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>node_count</th>\n",
       "      <th>degree</th>\n",
       "      <th>transitivity</th>\n",
       "      <th>centrality</th>\n",
       "      <th>average_clustering</th>\n",
       "      <th>number_connected_components</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-31 00:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>95</td>\n",
       "      <td>1.010526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.010750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-08-31 01:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>113</td>\n",
       "      <td>1.044248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.009324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-08-31 02:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>113</td>\n",
       "      <td>1.008850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.594042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.009008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-08-31 03:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380</td>\n",
       "      <td>669</td>\n",
       "      <td>1.136024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.632918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384</td>\n",
       "      <td>0.001701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-08-31 04:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194</td>\n",
       "      <td>359</td>\n",
       "      <td>1.080780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199</td>\n",
       "      <td>0.003019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Date  Close Price  pct_change  log_ret  \\\n",
       "0           0  2015-08-31 00:00:00         1.25         NaN      NaN   \n",
       "1           1  2015-08-31 01:00:00         1.25         0.0      0.0   \n",
       "2           2  2015-08-31 02:00:00         1.25         0.0      0.0   \n",
       "3           3  2015-08-31 03:00:00         1.25         0.0      0.0   \n",
       "4           4  2015-08-31 04:00:00         1.25         0.0      0.0   \n",
       "\n",
       "   edge_count  node_count    degree  transitivity  centrality  \\\n",
       "0          48          95  1.010526           0.0    0.568662   \n",
       "1          59         113  1.044248           0.0    0.580503   \n",
       "2          57         113  1.008850           0.0    0.594042   \n",
       "3         380         669  1.136024           0.0    0.632918   \n",
       "4         194         359  1.080780           0.0    0.665906   \n",
       "\n",
       "   average_clustering  number_connected_components   density  \n",
       "0                 0.0                           53  0.010750  \n",
       "1                 0.0                           64  0.009324  \n",
       "2                 0.0                           65  0.009008  \n",
       "3                 0.0                          384  0.001701  \n",
       "4                 0.0                          199  0.003019  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>log_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2015-08-31 00:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>389</td>\n",
       "      <td>2015-08-31 01:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>2015-08-31 02:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>404</td>\n",
       "      <td>2015-08-31 03:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>238</td>\n",
       "      <td>2015-08-31 04:00:00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count                 Date  Close Price  log_ret\n",
       "0           0     59  2015-08-31 00:00:00         1.25      NaN\n",
       "1           1    389  2015-08-31 01:00:00         1.25      0.0\n",
       "2           2    106  2015-08-31 02:00:00         1.25      0.0\n",
       "3           3    404  2015-08-31 03:00:00         1.25      0.0\n",
       "4           4    238  2015-08-31 04:00:00         1.25      0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.merge(p1,p2,on='Date')\n",
    "x.to_csv('final3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
